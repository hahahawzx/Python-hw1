{"title": "AI 公司 MosaicML 推出 300 亿参数模型 MPT-30B，号称训练成本仅为竞品零头AIgpu", "news_website": "新浪科技", "author": "", "Managing Editor": "", "details": {"creation_time": "2023年06月25日 14:19", "keywords": ["AI", "gpu"]}, "content": ["据悉，MosaicML 使用了 Alibi 和 FlashAttention 技术来优化模型，可以实现更长的文本长度和对 GPU 计算的更高利用率。MosaicML 也是少数几个能够使用 Nvidia H100 GPU 的实验室，相比以往成果，当下每块 GPU 的吞吐量增加了 2.4 倍以上，可带来更快的完成时间。", "除了让 AI 技术更容易获得之外，MosaicML 还专注于提高数据质量并提高模型性能。他们目前正在开发一款工具，可以帮助用户在预训练过程中分层加入特定领域的数据，以确保训练中开业实现多样化和高质量的数据组合。", "IT之家注意到，目前开发者可以从 Hugging Face 下载并使用开源的 MPT-30B 基础模型，开发者还可以在本地硬件上使用自己的数据，对模型进行微调。"], "urls": {"webpage": "https://finance.sina.com.cn/tech/digi/2023-06-25/doc-imyynrkn8235195.shtml", "image_url": ["https://n.sinaimg.cn/spider20230625/82/w1105h577/20230625/416d-a6d174fa870d6135cdf05bc53104df73.jpg"]}}