{"title": "新版摩尔定律也要靠算力 英伟达称AI训练速度可再提高1万倍英伟达", "news_website": "新浪财经", "author": "", "Managing Editor": "：郑卓", "details": {"creation_time": "2023年02月27日 20:00", "keywords": ["英伟达", "摩尔定律", "AI", "芯片"]}, "content": ["作者/钱童心", "ChatGPT之父、OpenAI公司CEO奥特曼（Sam Altman）周日在一条Twitter上写道：“新版摩尔定律很快就要来了，宇宙中的智能数量每18个月就会翻一倍。”", "奥特曼的最新言论很快在社交媒体上发酵，但他没有具体解释所谓的“智能”（intelligence）到底是指什么，这也引发了业内的热烈讨论。", "澜舟科技创始人CEO周明对第一财经记者表示，虽然神经元参数确实是可以数值化衡量的指标，但是过去几年里，神经元参数似乎并没有18个月就实现翻番。", "“我认为Altman说的意思比较含糊，我个人的理解是，世界上的人工智能能力每18个月翻一倍，但怎么才算翻一倍，是增加新的能力的个数，还是已有能力的翻倍提升，他没有明确说明。”周明对第一财经记者表示。", "第一财经记者就如何理解“智能”翻番向ChatGPT提问。首先问：“宇宙中智能数量每18个月翻一倍，这里的智能是指什么？”ChatGPT回答道：“声称宇宙中的智能数量每18个月翻番是没有科学依据的，因为智能不是一个可以用这种方式测量或量化的物理量，通常认为它是一个具有复杂特性的东西，不能简化为单个指标或者数值。”", "当第一财经记者在提问中加入ChatGPT创始人奥特曼的名字，再问：“奥特曼所说的新版摩尔定律是指什么？”ChatGPT回答称：“新摩尔定律指的是奥特曼在2018年做出的关于人工智能快速发展及其能力呈指数级增长的预测。奥特曼表示，人工智能发展的速度目前正在超过摩尔定律。”", "从ChatGPT的回答中可以看出，这一预测是奥特曼早在2018年就曾作出的，但当时OpenAI的能力远不如今天，这一表态自然也未受到关注。", "如今，奥特曼重新将他的“新版摩尔定律”抛出，背后是深度学习和AI的崛起。但不管ChatGPT如何强大，背后也离不开算力的支撑。", "随着人类对于算力的要求越来越高，要满足新的高性能运算需求，芯片就需要不断迭代，成本也会随之增加。目前支撑包括ChatGPT大模型在内的95%用于机器学习的芯片都是英伟达的A100，该芯片的单价超过1万美元。", "在上周英伟达的财报会议上，黄仁勋称，英伟达的GPU在过去的十年里将AI的处理性能提高了100万倍。英伟达现在希望将AI的训练速度提高至少1万倍。", "研究机构Gartner分析师盛陵海对第一财经记者表示：“过去十年是AI发展从0到100的阶段，但是要从100到10000，是完全不同的场景。过去十年芯片的发展还遵循摩尔定律，但随着摩尔定律接近极限，未来计算机的能力要进一步提升越来越困难，除非量子计算能有大的突破。”", "根据研究机构New Street Research发布的一份报告，英伟达的A100目前已成为人工智能领域的“主力”，占据了用于机器学习的图形处理器市场95%的份额。", "训练大型语言模型需要大量GPU，这些GPU还能进行“推理”。拥有热门AI产品的公司通常需要购买更多GPU来处理峰值期间的数据或用于模型的改进。例如，人工智能公司Stability AI公司过去一年购买的A100芯片数量增加到目前的5400个。Stability AI的软件用于图像生成器Stable Diffusion，使用256个A100芯片训练模型，训练总时长达20万个小时。", "但目前仅有大公司才有实力进行如此巨大的投资。为了让更多小公司能够使用英伟达AI的能力，英伟达正在拓展一种全新商业模式。黄仁勋在上周的财报电话会议中表示，未来将直接出售对DGX系统的云访问，从而降低小公司研究人员使用AI能力的入门成本。", "在黄仁勋看来，英伟达提供的价值是将原来需要投入10亿美元运行CPU的数据中心缩减为仅用1亿美元就能搞定的数据中心，现在将该数据中心放在云端共享，意味着可以由100家公司来分担这一成本，因此每家公司支付的实际上是非常少的费用。“现在企业可以花一两千万来构建一个类似GPT的大型语言模型，这是可以支付得起的。”黄仁勋表示。", "尽管英伟达并不是唯一一家生产用于人工智能GPU的公司，但根据研究机构State of AI的报告，截至去年12月，超过2万篇开源AI论文中都使用了英伟达的AI芯片，其中A100在2022年的使用量迅速增长，成为英伟达被使用第三多的芯片，仅次于其售价1500美元的游戏芯片。", "目前能与A100的使用量竞争的仍然是英伟达去年量产的下一代人工智能芯片H100。这款芯片的售价更高，并且在截至今年1月的财季中，H100芯片的收入已经超过了A100。英伟达表示，H100是该公司推出的首款针对transformer架构进行优化的数据中心GPU，transformer正在越来越多地用于新的顶级人工智能应用程序，重要性日益凸显。", "“H100采用了5纳米的制程，相比于A100的7纳米制程而言，H100的性能应该是显著优于A100的。”盛陵海对第一财经记者表示。"], "urls": {"webpage": "https://finance.sina.com.cn/tech/it/2023-02-27/doc-imyicwqr8188357.shtml", "image_url": ["https://n.sinaimg.cn/finance/transform/117/w550h367/20230227/783d-67d77897deb1aa83c5118cd3d7da3483.jpg"]}}