{"title": "研究人员发现 ChatGPT 生成的代码大部分不安全，但它不会主动告诉你研究人员", "news_website": "新浪科技", "author": "", "Managing Editor": "", "details": {"creation_time": "2023年04月23日 07:50", "keywords": ["研究人员"]}, "content": ["研究人员指出，ChatGPT 的部分问题是由于它没有考虑敌对的代码执行模型。它会反复告诉用户，安全问题可以通过“不输入无效的数据”来避免，但这在现实世界中是不可行的。然而，它似乎能够意识到并承认自己建议的代码中存在的关键漏洞。", "魁北克大学计算机科学与工程教授、论文的合著者之一 Raphaël Khoury 告诉《The Register》：“显然，它只是一个算法。它什么都不知道，但它可以识别出不安全的行为。”他说，最初 ChatGPT 对安全问题的回应是建议只使用有效的输入，这显然是不合理的。只有在之后被要求改进问题时，它才提供了有用的指导。", "Khoury 认为，ChatGPT 在目前的形式下是一个风险，但这并不是说没有合理使用这种不稳定、表现不佳的 AI 助手的方法。“我们已经看到学生使用这个工具，程序员也会在现实中使用这个工具。”他说，“所以拥有一个生成不安全代码的工具是非常危险的。我们需要让学生意识到，如果代码是用这种类型的工具生成的，那么它很可能是不安全的。”他还称，让他感到惊讶的是，当他们让 ChatGPT 生成相同任务的不同语言的代码时，有时对于一种语言，它会生成安全的代码，而对于另一种语言，它会生成有漏洞的代码，“因为这种语言模型有点像一个黑盒子，我真的没有一个很好的解释或理论来说明这一点。”"], "urls": {"webpage": "https://finance.sina.com.cn/tech/mobile/n/n/2023-04-23/doc-imyrikkx5240261.shtml", "image_url": ["https://n.sinaimg.cn/spider20230423/0/w1440h960/20230423/19e9-ba03144b93c4c6f2749118df2fe2ee43.jpg"]}}